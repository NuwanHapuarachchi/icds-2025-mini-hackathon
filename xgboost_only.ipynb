{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f9a2bf",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee990b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "XGBoost version: 3.0.4\n",
      "Optuna version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Optuna for hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b994de7",
   "metadata": {},
   "source": [
    "## 2. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c2b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CUDA is available\n",
      "✓ GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "✓ CUDA version: 12.8\n",
      "\n",
      "XGBoost will use: tree_method='gpu_hist', device='cuda'\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability\n",
    "try:\n",
    "    import torch\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if cuda_available:\n",
    "        print(f\"✓ CUDA is available\")\n",
    "        print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"⚠ CUDA not available, will use CPU\")\n",
    "except:\n",
    "    print(\"⚠ PyTorch not installed, checking XGBoost GPU support directly\")\n",
    "    cuda_available = False\n",
    "\n",
    "# Set tree method based on GPU availability\n",
    "TREE_METHOD = 'gpu_hist' if cuda_available else 'hist'\n",
    "DEVICE = 'cuda' if cuda_available else 'cpu'\n",
    "\n",
    "print(f\"\\nXGBoost will use: tree_method='{TREE_METHOD}', device='{DEVICE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a038ab",
   "metadata": {},
   "source": [
    "## 3. Load Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5deecf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1500, 46)\n",
      "Test shape: (377, 45)\n",
      "\n",
      "Target distribution:\n",
      "drug_category\n",
      "Hallucinogens    691\n",
      "Stimulants       567\n",
      "Depressants      242\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "drug_category\n",
      "Hallucinogens    46.066667\n",
      "Stimulants       37.800000\n",
      "Depressants      16.133333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Features shape: (1500, 45)\n",
      "Test features shape: (377, 45)\n",
      "\n",
      "Class encoding: {0: 'Depressants', 1: 'Hallucinogens', 2: 'Stimulants'}\n",
      "\n",
      "Feature names: ['ID', 'Age', 'Education', 'Nscore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS', 'HighRisk_Score', 'SensationRisk_Score', 'EmotionalInstability', 'Social_Risk', 'Behavioral_Disinhibition', 'NE_Balance', 'BigFive_Std', 'RiskFactor_Mean', 'Impulsive_x_SS', 'Nscore_x_SS', 'Escore_x_Oscore', 'Cscore_x_SS', 'Oscore_x_Impulsive', 'Nscore_squared', 'Nscore_cubed', 'Escore_squared', 'Ascore_squared', 'Impulsive_squared', 'Impulsive_cubed', 'SS_squared', 'SS_cubed', 'Impulsive_to_Cscore_ratio', 'SS_to_Cscore_ratio', 'Nscore_to_Ascore_ratio', 'Risk_to_Protective_ratio', 'OC_ratio', 'Impulsive_Level', 'SS_Level', 'Nscore_Level', 'Cscore_Level', 'Gender_0.48246', 'Country_-0.28519', 'Country_-0.09765', 'Country_0.96082', 'Ethnicity_-0.50212', 'Ethnicity_-0.31685']\n"
     ]
    }
   ],
   "source": [
    "# Load engineered datasets\n",
    "train_df = pd.read_csv('data/data_minihackathon_train_engineered.csv')\n",
    "test_df = pd.read_csv('data/data_minihackathon_test_engineered.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df['drug_category'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(train_df['drug_category'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_df.drop(['drug_category', 'id'], axis=1, errors='ignore')\n",
    "y = train_df['drug_category']\n",
    "X_test = test_df.drop(['id'], axis=1, errors='ignore')\n",
    "test_ids = test_df['id'] if 'id' in test_df.columns else np.arange(len(test_df))\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"\\nClass encoding: {dict(enumerate(le.classes_))}\")\n",
    "print(f\"\\nFeature names: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654336d",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10-fold stratified cross-validation\n",
      "Random state: 42\n",
      "Optuna trials: 50\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "N_FOLDS = 10\n",
    "RANDOM_STATE = 42\n",
    "N_TRIALS = 20  # Number of Optuna trials (increase for better optimization)\n",
    "\n",
    "# Stratified K-Fold for cross-validation\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Using {N_FOLDS}-fold stratified cross-validation\")\n",
    "print(f\"Random state: {RANDOM_STATE}\")\n",
    "print(f\"Optuna trials: {N_TRIALS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f660059",
   "metadata": {},
   "source": [
    "## 5. XGBoost Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b30897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 15:26:55,545] A new study created in memory with name: xgboost_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "XGBoost Hyperparameter Optimization with Optuna\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.708:   2%|▏         | 1/50 [00:19<15:50, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 15:27:14,930] Trial 0 finished with value: 0.708 and parameters: {'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.01980403666076474, 'min_child_weight': 8, 'subsample': 0.7595222843319884, 'colsample_bytree': 0.7705417604662863, 'gamma': 0.09193289652122782, 'reg_alpha': 2.018536773073783, 'reg_lambda': 3.972051387668687}. Best is trial 0 with value: 0.708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.716:   4%|▍         | 2/50 [00:48<20:11, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 15:27:44,267] Trial 1 finished with value: 0.716 and parameters: {'n_estimators': 305, 'max_depth': 5, 'learning_rate': 0.019171288116434055, 'min_child_weight': 2, 'subsample': 0.6288869932030002, 'colsample_bytree': 0.6005691175115523, 'gamma': 0.458220835655046, 'reg_alpha': 4.408766354278014, 'reg_lambda': 4.867849813651781}. Best is trial 1 with value: 0.716.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.716:   6%|▌         | 3/50 [02:01<36:36, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 15:28:56,563] Trial 2 finished with value: 0.712 and parameters: {'n_estimators': 926, 'max_depth': 6, 'learning_rate': 0.0037486045046647765, 'min_child_weight': 1, 'subsample': 0.6023313645160633, 'colsample_bytree': 0.9721810776217322, 'gamma': 0.40945713181840415, 'reg_alpha': 4.059071560664168, 'reg_lambda': 4.363298956759931}. Best is trial 1 with value: 0.716.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.716:   6%|▌         | 3/50 [02:55<45:46, 58.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-16 15:29:50,847] Trial 3 failed with parameters: {'n_estimators': 729, 'max_depth': 6, 'learning_rate': 0.0017642737489484866, 'min_child_weight': 5, 'subsample': 0.8880673120629803, 'colsample_bytree': 0.8712197112986811, 'gamma': 0.8810732971275737, 'reg_alpha': 0.8973697760086824, 'reg_lambda': 3.0522352767974152} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"<timed exec>\", line 25, in objective_xgb\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 399, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py\", line 2072, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py\", line 1682, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py\", line 1800, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-16 15:29:50,874] Trial 3 failed with value None.\n",
      "CPU times: total: 1.19 s\n",
      "Wall time: 2min 55s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m + \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mXGBoost Hyperparameter Optimization with Optuna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdef objective_xgb(trial):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptuna objective function for XGBoost hyperparameter optimization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    params = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mn_estimators\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_int(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mn_estimators\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 100, 1000),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmax_depth\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_int(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmax_depth\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 3, 12),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0.001, 0.2, log=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmin_child_weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_int(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmin_child_weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 1, 10),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43msubsample\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43msubsample\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0.6, 1.0),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mcolsample_bytree\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mcolsample_bytree\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0.6, 1.0),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mgamma\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mgamma\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0, 1.0),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mreg_alpha\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mreg_alpha\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0, 5),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mreg_lambda\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: trial.suggest_float(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mreg_lambda\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, 0, 5),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mrandom_state\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: RANDOM_STATE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mtree_method\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: TREE_METHOD,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mdevice\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: DEVICE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43meval_metric\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmlogloss\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Cross-validation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    model = xgb.XGBClassifier(**params)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cv_results = cross_validate(model, X, y_encoded, cv=skf, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                               scoring=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43maccuracy\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, n_jobs=-1)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return cv_results[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mtest_score\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m].mean()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Create and run Optuna study\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mstudy = optuna.create_study(direction=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mmaximize\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m, study_name=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mxgboost_optimization\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mstudy.optimize(objective_xgb, n_trials=N_TRIALS, show_progress_bar=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m*80}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPTIMIZATION RESULTS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*80)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBest CV Accuracy: \u001b[39;49m\u001b[38;5;132;43;01m{study.best_value:.4f}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mnBest parameters:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfor key, value in study.best_params.items():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m  \u001b[39;49m\u001b[38;5;132;43;01m{key}\u001b[39;49;00m\u001b[33;43m: \u001b[39;49m\u001b[38;5;132;43;01m{value}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1434\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1432\u001b[39m st = clock2()\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:32\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:25\u001b[39m, in \u001b[36mobjective_xgb\u001b[39m\u001b[34m(trial)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBoost Hyperparameter Optimization with Optuna\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    \"\"\"Optuna objective function for XGBoost hyperparameter optimization\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.2, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'tree_method': TREE_METHOD,\n",
    "        'device': DEVICE,\n",
    "        'eval_metric': 'mlogloss'\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    cv_results = cross_validate(model, X, y_encoded, cv=skf, \n",
    "                               scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    return cv_results['test_score'].mean()\n",
    "\n",
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction='maximize', study_name='xgboost_optimization')\n",
    "study.optimize(objective_xgb, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best CV Accuracy: {study.best_value:.4f}\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e8d38",
   "metadata": {},
   "source": [
    "## 6. Visualize Optimization History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations directory\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "# Plot optimization history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Optimization history\n",
    "trial_numbers = [trial.number for trial in study.trials]\n",
    "trial_values = [trial.value for trial in study.trials]\n",
    "best_values = [max(trial_values[:i+1]) for i in range(len(trial_values))]\n",
    "\n",
    "axes[0].plot(trial_numbers, trial_values, 'o-', alpha=0.6, label='Trial Accuracy')\n",
    "axes[0].plot(trial_numbers, best_values, 'r-', linewidth=2, label='Best Accuracy')\n",
    "axes[0].set_xlabel('Trial Number')\n",
    "axes[0].set_ylabel('CV Accuracy')\n",
    "axes[0].set_title('Optuna Optimization History')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter importance (if enough trials)\n",
    "if len(study.trials) >= 10:\n",
    "    try:\n",
    "        importance = optuna.importance.get_param_importances(study)\n",
    "        params = list(importance.keys())\n",
    "        values = list(importance.values())\n",
    "        \n",
    "        axes[1].barh(params, values)\n",
    "        axes[1].set_xlabel('Importance')\n",
    "        axes[1].set_title('Hyperparameter Importance')\n",
    "        axes[1].grid(True, alpha=0.3, axis='x')\n",
    "    except:\n",
    "        axes[1].text(0.5, 0.5, 'Insufficient trials for importance analysis', \n",
    "                    ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].axis('off')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Insufficient trials for importance analysis', \n",
    "                ha='center', va='center', transform=axes[1].transAxes)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/xgboost_optimization_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimization visualization saved to: visualizations/xgboost_optimization_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97675122",
   "metadata": {},
   "source": [
    "## 7. Train Final Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training Final XGBoost Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create model with best parameters\n",
    "best_xgb = xgb.XGBClassifier(**study.best_params)\n",
    "\n",
    "# Evaluate with cross-validation\n",
    "cv_results = cross_validate(best_xgb, X, y_encoded, cv=skf,\n",
    "                           scoring=['accuracy', 'f1_macro'], \n",
    "                           return_train_score=True)\n",
    "\n",
    "cv_accuracy = cv_results['test_accuracy'].mean()\n",
    "cv_std = cv_results['test_accuracy'].std()\n",
    "f1_macro = cv_results['test_f1_macro'].mean()\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  CV Accuracy: {cv_accuracy:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"  F1-Macro: {f1_macro:.4f}\")\n",
    "print(f\"  Fold Accuracies: {cv_results['test_accuracy']}\")\n",
    "\n",
    "# Train on full training data\n",
    "print(f\"\\nTraining on full dataset...\")\n",
    "best_xgb.fit(X, y_encoded)\n",
    "\n",
    "# Training predictions\n",
    "train_pred = best_xgb.predict(X)\n",
    "train_accuracy = accuracy_score(y_encoded, train_pred)\n",
    "\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report (Training):\")\n",
    "print(classification_report(y_encoded, train_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018acb0a",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99554de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_encoded, train_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('XGBoost - Confusion Matrix (Training)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "\n",
    "# Add accuracy text\n",
    "plt.text(1.5, -0.3, f'Training Accuracy: {train_accuracy:.4f}', \n",
    "         fontsize=12, fontweight='bold', ha='center')\n",
    "plt.text(1.5, -0.5, f'CV Accuracy: {cv_accuracy:.4f} ± {cv_std:.4f}', \n",
    "         fontsize=12, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/xgboost_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved to: visualizations/xgboost_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87a913",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc85702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20 = feature_importance.head(20)\n",
    "plt.barh(top_20['feature'], top_20['importance'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('XGBoost - Top 20 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/xgboost_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature importance visualization saved to: visualizations/xgboost_feature_importance.png\")\n",
    "\n",
    "# Save full feature importance\n",
    "feature_importance.to_csv('visualizations/xgboost_feature_importance.csv', index=False)\n",
    "print(\"Full feature importance saved to: visualizations/xgboost_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeab271",
   "metadata": {},
   "source": [
    "## 10. Generate Test Predictions and Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Generating Test Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_pred_encoded = best_xgb.predict(X_test)\n",
    "test_pred = le.inverse_transform(test_pred_encoded)\n",
    "\n",
    "# Get prediction probabilities\n",
    "test_pred_proba = best_xgb.predict_proba(X_test)\n",
    "\n",
    "print(f\"\\nTest predictions generated: {len(test_pred)}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "pred_dist = pd.Series(test_pred).value_counts()\n",
    "print(pred_dist)\n",
    "print(f\"\\nPrediction percentages:\")\n",
    "print(pred_dist / len(test_pred) * 100)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'drug_category': test_pred\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission_filename = f\"submission_xgboost_{timestamp}.csv\"\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUBMISSION FILE CREATED: {submission_filename}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "print(f\"\\nLast 10 predictions:\")\n",
    "print(submission.tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211dd4f",
   "metadata": {},
   "source": [
    "## 11. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save model\n",
    "model_filename = f\"models/xgboost_model_{timestamp}.pkl\"\n",
    "joblib.dump(best_xgb, model_filename)\n",
    "print(f\"Model saved: {model_filename}\")\n",
    "\n",
    "# Save label encoder\n",
    "le_filename = f\"models/label_encoder_{timestamp}.pkl\"\n",
    "joblib.dump(le, le_filename)\n",
    "print(f\"Label encoder saved: {le_filename}\")\n",
    "\n",
    "# Save optimization study\n",
    "study_filename = f\"models/optuna_study_{timestamp}.pkl\"\n",
    "joblib.dump(study, study_filename)\n",
    "print(f\"Optuna study saved: {study_filename}\")\n",
    "\n",
    "# Save results summary\n",
    "results = {\n",
    "    'timestamp': timestamp,\n",
    "    'cv_accuracy': cv_accuracy,\n",
    "    'cv_std': cv_std,\n",
    "    'f1_macro': f1_macro,\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'best_params': study.best_params,\n",
    "    'n_trials': N_TRIALS,\n",
    "    'n_folds': N_FOLDS,\n",
    "    'tree_method': TREE_METHOD,\n",
    "    'device': DEVICE\n",
    "}\n",
    "\n",
    "results_filename = f\"models/xgboost_results_{timestamp}.pkl\"\n",
    "joblib.dump(results, results_filename)\n",
    "print(f\"Results saved: {results_filename}\")\n",
    "\n",
    "# Save results as JSON for easy viewing\n",
    "import json\n",
    "results_json_filename = f\"models/xgboost_results_{timestamp}.json\"\n",
    "with open(results_json_filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Results (JSON) saved: {results_json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eddcde",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c387c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBOOST TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE METRICS:\")\n",
    "print(f\"  ├─ Cross-Validation Accuracy: {cv_accuracy:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"  ├─ F1-Macro Score: {f1_macro:.4f}\")\n",
    "print(f\"  └─ Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n⚙️  CONFIGURATION:\")\n",
    "print(f\"  ├─ Optimization Trials: {N_TRIALS}\")\n",
    "print(f\"  ├─ Cross-Validation Folds: {N_FOLDS}\")\n",
    "print(f\"  ├─ Tree Method: {TREE_METHOD}\")\n",
    "print(f\"  └─ Device: {DEVICE}\")\n",
    "\n",
    "print(f\"\\n🎯 BEST HYPERPARAMETERS:\")\n",
    "for key, value in study.best_params.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  ├─ {key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"  ├─ {key}: {value}\")\n",
    "\n",
    "print(f\"\\n📁 FILES GENERATED:\")\n",
    "print(f\"  ├─ Submission: {submission_filename}\")\n",
    "print(f\"  ├─ Model: {model_filename}\")\n",
    "print(f\"  ├─ Label Encoder: {le_filename}\")\n",
    "print(f\"  ├─ Optuna Study: {study_filename}\")\n",
    "print(f\"  ├─ Results (JSON): {results_json_filename}\")\n",
    "print(f\"  └─ Visualizations: visualizations/\")\n",
    "\n",
    "print(f\"\\n📈 PREDICTION DISTRIBUTION:\")\n",
    "for category, count in pred_dist.items():\n",
    "    percentage = (count / len(test_pred)) * 100\n",
    "    print(f\"  ├─ {category}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✅ READY FOR SUBMISSION: {submission_filename}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
