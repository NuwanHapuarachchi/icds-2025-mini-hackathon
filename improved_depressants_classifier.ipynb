{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, \n",
    "    confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SMOTE for oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Models\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('data/data_minihackathon_train_engineered.csv')\n",
    "test_df = pd.read_csv('data/data_minihackathon_test_engineered.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Create binary labels\n",
    "X = train_df.drop(['drug_category', 'id'], axis=1, errors='ignore')\n",
    "y_original = train_df['drug_category']\n",
    "X_test = test_df.drop(['ID', 'id'], axis=1, errors='ignore')\n",
    "test_ids = range(501, 501 + len(test_df))\n",
    "\n",
    "y_binary = (y_original == 'Depressants').astype(int)\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Depressants: {y_binary.sum()} ({y_binary.sum()/len(y_binary)*100:.2f}%)\")\n",
    "print(f\"  Others: {(y_binary == 0).sum()} ({(y_binary == 0).sum()/len(y_binary)*100:.2f}%)\")\n",
    "print(f\"  Imbalance ratio: 1:{(y_binary == 0).sum() / y_binary.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e23d9",
   "metadata": {},
   "source": [
    "## Strategy 1: XGBoost with Extreme Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBoost with AGGRESSIVE Class Weighting (Prioritize Recall)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggressive scale_pos_weight to force model to catch Depressants\n",
    "scale_pos_weight = (y_binary == 0).sum() / y_binary.sum() * 1.5  # 1.5x boost\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    min_child_weight=1,  # Lower to allow smaller leaf nodes\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0,  # No regularization on splits\n",
    "    reg_alpha=0.1,  # Light L1\n",
    "    reg_lambda=0.5,  # Light L2\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    device='cpu',\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Train and predict\n",
    "xgb_model.fit(X, y_binary)\n",
    "xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\n✓ XGBoost trained\")\n",
    "print(f\"Probability range: {xgb_proba.min():.4f} - {xgb_proba.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012cdf9",
   "metadata": {},
   "source": [
    "## Strategy 2: LightGBM with Balanced Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LightGBM with Balanced Class Weighting\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    num_leaves=50,\n",
    "    learning_rate=0.03,\n",
    "    min_data_in_leaf=10,  # Lower to allow smaller groups\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    class_weight='balanced',  # Auto-balance\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "lgb_model.fit(X, y_binary)\n",
    "lgb_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"✓ LightGBM trained\")\n",
    "print(f\"Probability range: {lgb_proba.min():.4f} - {lgb_proba.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8193a24",
   "metadata": {},
   "source": [
    "## Strategy 3: Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dfbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Random Forest with SMOTE Oversampling\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Apply SMOTE to create synthetic Depressants samples\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y_binary)\n",
    "\n",
    "print(f\"Original: {y_binary.sum()} Depressants, {(y_binary==0).sum()} Others\")\n",
    "print(f\"After SMOTE: {y_resampled.sum()} Depressants, {(y_resampled==0).sum()} Others\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"✓ Random Forest trained on balanced data\")\n",
    "print(f\"Probability range: {rf_proba.min():.4f} - {rf_proba.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f2486",
   "metadata": {},
   "source": [
    "## Ensemble: Average Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE: Averaging All Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Average probabilities from all models\n",
    "ensemble_proba = (xgb_proba + lgb_proba + rf_proba) / 3\n",
    "\n",
    "print(f\"\\nEnsemble probability statistics:\")\n",
    "print(f\"  Min: {ensemble_proba.min():.4f}\")\n",
    "print(f\"  Max: {ensemble_proba.max():.4f}\")\n",
    "print(f\"  Mean: {ensemble_proba.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(ensemble_proba):.4f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'id': list(test_ids),\n",
    "    'xgb_proba': xgb_proba,\n",
    "    'lgb_proba': lgb_proba,\n",
    "    'rf_proba': rf_proba,\n",
    "    'ensemble_proba': ensemble_proba\n",
    "})\n",
    "\n",
    "# Sort by ensemble probability\n",
    "results_df = results_df.sort_values('ensemble_proba', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTop 20 most likely Depressants:\")\n",
    "print(results_df.head(20)[['id', 'ensemble_proba']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783c705",
   "metadata": {},
   "source": [
    "## Select Top 63 as Depressants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL PREDICTIONS: Top 63 Samples as Depressants\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select top 63 (confirmed ground truth count)\n",
    "n_depressants = 63\n",
    "top_63_ids = results_df.head(n_depressants)['id'].tolist()\n",
    "\n",
    "# Create predictions\n",
    "results_df['prediction'] = results_df['id'].apply(\n",
    "    lambda x: 'Depressants' if x in top_63_ids else 'Others'\n",
    ")\n",
    "\n",
    "threshold = results_df.iloc[n_depressants-1]['ensemble_proba']\n",
    "print(f\"\\nThreshold used: {threshold:.4f}\")\n",
    "print(f\"Depressants predicted: {(results_df['prediction'] == 'Depressants').sum()}\")\n",
    "\n",
    "# Check your confirmed IDs\n",
    "confirmed_ids = [513, 521, 570, 642, 770]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"VALIDATION ON YOUR CONFIRMED DEPRESSANTS:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for conf_id in confirmed_ids:\n",
    "    row = results_df[results_df['id'] == conf_id].iloc[0]\n",
    "    rank = results_df[results_df['id'] == conf_id].index[0] + 1\n",
    "    status = \"✓ CAUGHT\" if row['prediction'] == 'Depressants' else \"❌ MISSED\"\n",
    "    print(f\"\\nID {conf_id}:\")\n",
    "    print(f\"  Ensemble prob: {row['ensemble_proba']:.4f}\")\n",
    "    print(f\"  Rank: {rank}/{len(results_df)}\")\n",
    "    print(f\"  Prediction: {row['prediction']} {status}\")\n",
    "\n",
    "caught = sum([1 for cid in confirmed_ids if cid in top_63_ids])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Caught {caught}/{len(confirmed_ids)} of your confirmed Depressants ({caught/len(confirmed_ids)*100:.1f}%)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80aa44",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = results_df[['id', 'prediction']].copy()\n",
    "submission.columns = ['id', 'drug_category']\n",
    "submission = submission.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f\"submission_IMPROVED_ensemble_{timestamp}.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✅ SUBMISSION CREATED: {filename}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission['drug_category'].value_counts())\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "# Save detailed results\n",
    "os.makedirs('binary_predictions', exist_ok=True)\n",
    "results_df.to_csv(f'binary_predictions/improved_ensemble_detailed_{timestamp}.csv', index=False)\n",
    "print(f\"\\n✅ Detailed results: binary_predictions/improved_ensemble_detailed_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535162ba",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Ensemble probability distribution\n",
    "axes[0, 0].hist(ensemble_proba, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {threshold:.3f}')\n",
    "axes[0, 0].set_xlabel('Ensemble Probability')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Ensemble Probability Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Model comparison\n",
    "model_names = ['XGBoost', 'LightGBM', 'RF+SMOTE', 'Ensemble']\n",
    "model_probas = [xgb_proba, lgb_proba, rf_proba, ensemble_proba]\n",
    "means = [p.mean() for p in model_probas]\n",
    "axes[0, 1].bar(model_names, means, color=['steelblue', 'coral', 'lightgreen', 'gold'], edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Mean Probability')\n",
    "axes[0, 1].set_title('Average Depressant Probability by Model')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Top 80 probabilities\n",
    "top_80 = results_df.head(80)\n",
    "colors = ['red' if p == 'Depressants' else 'blue' for p in top_80['prediction']]\n",
    "axes[1, 0].scatter(range(len(top_80)), top_80['ensemble_proba'], c=colors, alpha=0.6)\n",
    "axes[1, 0].axhline(y=threshold, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 0].set_xlabel('Rank')\n",
    "axes[1, 0].set_ylabel('Ensemble Probability')\n",
    "axes[1, 0].set_title('Top 80 Samples by Probability (Red=Depressants, Blue=Others)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Prediction counts\n",
    "pred_counts = submission['drug_category'].value_counts()\n",
    "axes[1, 1].bar(pred_counts.index, pred_counts.values, color=['steelblue', 'coral'], edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Final Prediction Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(pred_counts.values):\n",
    "    axes[1, 1].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "plt.savefig('visualizations/improved_ensemble_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved: visualizations/improved_ensemble_analysis.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
