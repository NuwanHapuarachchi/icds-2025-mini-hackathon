{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e75d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da32c68",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05d4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1500, 46)\n",
      "Test data shape: (377, 45)\n",
      "\n",
      "Class distribution BEFORE balancing:\n",
      "drug_category\n",
      "Hallucinogens    691\n",
      "Stimulants       567\n",
      "Depressants      242\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "drug_category\n",
      "Hallucinogens    46.066667\n",
      "Stimulants       37.800000\n",
      "Depressants      16.133333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('data/data_minihackathon_train_engineered.csv')\n",
    "test_df = pd.read_csv('data/data_minihackathon_test_engineered.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"\\nClass distribution BEFORE balancing:\")\n",
    "print(train_df['drug_category'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(train_df['drug_category'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4f82f",
   "metadata": {},
   "source": [
    "## Balance Dataset Using Undersampling\n",
    "We'll undersample Hallucinogens and Stimulants to match Depressants frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a86ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1500, 45)\n",
      "Target shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = train_df.drop(['drug_category'], axis=1)\n",
    "y = train_df['drug_category']\n",
    "\n",
    "# Check for ID column and drop it\n",
    "if 'id' in X.columns:\n",
    "    X = X.drop(['id'], axis=1)\n",
    "\n",
    "# Encode labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_encoded = label_encoder.fit_transform(y)print(f\"\\nLabel encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a66d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balancing Strategy: Equal representation for all classes\n",
      "Target samples per class: 242\n",
      "\n",
      "Balanced dataset shape: (726, 45)\n",
      "\n",
      "Class distribution AFTER balancing:\n",
      "drug_category\n",
      "Depressants      242\n",
      "Hallucinogens    242\n",
      "Stimulants       242\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "drug_category\n",
      "Depressants      33.333333\n",
      "Hallucinogens    33.333333\n",
      "Stimulants       33.333333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Strategy 1: Balance all classes equally (1:1:1 ratio)\n",
    "# This gives each class equal representation\n",
    "\n",
    "# Count samples per class\n",
    "class_counts = y.value_counts()\n",
    "min_class_count = class_counts.min()\n",
    "\n",
    "print(f\"\\nBalancing Strategy: Equal representation for all classes\")\n",
    "print(f\"Target samples per class: {min_class_count}\")\n",
    "\n",
    "# Use RandomUnderSampler to balance classes\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Create balanced dataset (1:1:1 ratio)\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_balanced, y_balanced_encoded = undersampler.fit_resample(X, y_encoded)\n",
    "\n",
    "# Decode back to string labels for display\n",
    "y_balanced = label_encoder.inverse_transform(y_balanced_encoded)\n",
    "\n",
    "print(f\"\\nBalanced dataset shape: {X_balanced.shape}\")\n",
    "print(f\"\\nClass distribution AFTER balancing:\")\n",
    "\n",
    "print(pd.Series(y_balanced).value_counts())print(pd.Series(y_balanced).value_counts(normalize=True) * 100)\n",
    "print(f\"\\nPercentages:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3549033",
   "metadata": {},
   "source": [
    "## Train-Test Split for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (580, 45)\n",
      "Validation set: (146, 45)\n",
      "\n",
      "Training set class distribution:\n",
      "drug_category\n",
      "Depressants      194\n",
      "Stimulants       193\n",
      "Hallucinogens    193\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split balanced data for validation\n",
    "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(\n",
    "    X_balanced, y_balanced_encoded, test_size=0.2, random_state=42, stratify=y_balanced_encoded\n",
    ")\n",
    "\n",
    "# Keep string versions for display\n",
    "y_train = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_val = label_encoder.inverse_transform(y_val_encoded)\n",
    "\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")print(pd.Series(y_train).value_counts())\n",
    "\n",
    "print(f\"Validation set: {X_val.shape}\")print(f\"\\nTraining set class distribution:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57923978",
   "metadata": {},
   "source": [
    "## Train Multiple Models on Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Depressants' 'Hallucinogens' 'Stimulants']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      2\u001b[39m xgb_model = XGBClassifier(\n\u001b[32m      3\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m      4\u001b[39m     max_depth=\u001b[32m6\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     tree_method=\u001b[33m'\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining XGBoost...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m xgb_pred = xgb_model.predict(X_val)\n\u001b[32m     16\u001b[39m xgb_acc = accuracy_score(y_val, xgb_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\anaconda3\\envs\\Vision\\Lib\\site-packages\\xgboost\\sklearn.py:1641\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1636\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1638\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1639\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1640\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1642\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1643\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1644\u001b[39m     )\n\u001b[32m   1646\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Depressants' 'Hallucinogens' 'Stimulants']"
     ]
    }
   ],
   "source": [
    "# Model 1: XGBoost with balanced classes\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "xgb_pred_encoded = xgb_model.predict(X_val)\n",
    "xgb_pred = label_encoder.inverse_transform(xgb_pred_encoded)\n",
    "xgb_acc = accuracy_score(y_val, xgb_pred)\n",
    "print(f\"XGBoost Validation Accuracy: {xgb_acc:.4f}\")\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_val, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddb7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: LightGBM with balanced classes\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "lgbm_model.fit(X_train, y_train_encoded)\n",
    "lgbm_pred_encoded = lgbm_model.predict(X_val)\n",
    "lgbm_pred = label_encoder.inverse_transform(lgbm_pred_encoded)\n",
    "lgbm_acc = accuracy_score(y_val, lgbm_pred)\n",
    "print(f\"LightGBM Validation Accuracy: {lgbm_acc:.4f}\")\n",
    "print(\"\\nLightGBM Classification Report:\")\n",
    "print(classification_report(y_val, lgbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest with balanced classes\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model.fit(X_train, y_train_encoded)\n",
    "rf_pred_encoded = rf_model.predict(X_val)\n",
    "rf_pred = label_encoder.inverse_transform(rf_pred_encoded)\n",
    "rf_acc = accuracy_score(y_val, rf_pred)\n",
    "print(f\"Random Forest Validation Accuracy: {rf_acc:.4f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_val, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training Gradient Boosting...\")\n",
    "gb_model.fit(X_train, y_train_encoded)\n",
    "gb_pred_encoded = gb_model.predict(X_val)\n",
    "gb_pred = label_encoder.inverse_transform(gb_pred_encoded)\n",
    "gb_acc = accuracy_score(y_val, gb_pred)\n",
    "print(f\"Gradient Boosting Validation Accuracy: {gb_acc:.4f}\")\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_val, gb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f94e3",
   "metadata": {},
   "source": [
    "## Create Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create voting ensemble with soft voting (uses probabilities)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"Training Voting Ensemble...\")\n",
    "voting_clf.fit(X_train, y_train_encoded)\n",
    "voting_pred_encoded = voting_clf.predict(X_val)\n",
    "voting_pred = label_encoder.inverse_transform(voting_pred_encoded)\n",
    "voting_acc = accuracy_score(y_val, voting_pred)\n",
    "print(f\"Voting Ensemble Validation Accuracy: {voting_acc:.4f}\")\n",
    "print(\"\\nVoting Ensemble Classification Report:\")\n",
    "print(classification_report(y_val, voting_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec63729",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'LightGBM', 'Random Forest', 'Gradient Boosting', 'Voting Ensemble'],\n",
    "    'Accuracy': [xgb_acc, lgbm_acc, rf_acc, gb_acc, voting_acc]\n",
    "})\n",
    "\n",
    "results = results.sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON (sorted by accuracy)\")\n",
    "print(\"=\"*50)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "best_accuracy = results.iloc[0]['Accuracy']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} with accuracy {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd625e3",
   "metadata": {},
   "source": [
    "## Cross-Validation on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd25cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on the voting ensemble\n",
    "cv_scores = cross_val_score(\n",
    "    voting_clf, X_balanced, y_balanced_encoded, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nCross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2866423",
   "metadata": {},
   "source": [
    "## Check Confusion Matrix for All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for voting ensemble\n",
    "cm = confusion_matrix(y_val, voting_pred)\n",
    "classes = sorted(y_balanced.unique())\n",
    "\n",
    "print(\"\\nConfusion Matrix (Voting Ensemble):\")\n",
    "cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "print(cm_df)\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for i, cls in enumerate(classes):\n",
    "    class_acc = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"{cls}: {class_acc:.4f} ({cm[i, i]}/{cm[i, :].sum()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ae4dc",
   "metadata": {},
   "source": [
    "## Retrain on Full Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain voting ensemble on full balanced dataset\n",
    "print(\"Retraining Voting Ensemble on full balanced dataset...\")\n",
    "\n",
    "# Recreate models with same parameters\n",
    "final_xgb = XGBClassifier(\n",
    "    n_estimators=500, max_depth=6, learning_rate=0.05, subsample=0.8,\n",
    "    colsample_bytree=0.8, random_state=42, eval_metric='mlogloss', tree_method='hist'\n",
    ")\n",
    "\n",
    "final_lgbm = LGBMClassifier(\n",
    "    n_estimators=500, max_depth=6, learning_rate=0.05, subsample=0.8,\n",
    "    colsample_bytree=0.8, random_state=42, verbose=-1\n",
    ")\n",
    "\n",
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=10, min_samples_split=5,\n",
    "    min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "final_gb = GradientBoostingClassifier(\n",
    "    n_estimators=300, max_depth=5, learning_rate=0.05,\n",
    "    subsample=0.8, random_state=42\n",
    ")\n",
    "\n",
    "# Create final voting ensemble\n",
    "final_voting = VotingClassifier(\n",
    "    estimators=[('xgb', final_xgb), ('lgbm', final_lgbm), ('rf', final_rf), ('gb', final_gb)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train on full balanced dataset\n",
    "final_voting.fit(X_balanced, y_balanced)\n",
    "print(\"‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fe6eb",
   "metadata": {},
   "source": [
    "## Prepare Test Data and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# Drop ID column if present\n",
    "if 'id' in X_test.columns:\n",
    "    X_test = X_test.drop(['id'], axis=1)\n",
    "\n",
    "# Ensure test data has same columns as training data\n",
    "missing_cols = set(X_balanced.columns) - set(X_test.columns)\n",
    "extra_cols = set(X_test.columns) - set(X_balanced.columns)\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Test data missing columns: {missing_cols}\")\n",
    "if extra_cols:\n",
    "    print(f\"Warning: Test data has extra columns: {extra_cols}\")\n",
    "    X_test = X_test[X_balanced.columns]\n",
    "\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Expected shape: ({len(test_df)}, {X_balanced.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "predictions = final_voting.predict(X_test)\n",
    "prediction_probs = final_voting.predict_proba(X_test)\n",
    "\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pd.Series(predictions).value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(pd.Series(predictions).value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb421c",
   "metadata": {},
   "source": [
    "## Validate Against Known Depressants IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check predictions for confirmed Depressants IDs\n",
    "confirmed_depressants = [513, 521, 570, 642, 770]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION: Checking Confirmed Depressants IDs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get class names\n",
    "class_names = final_voting.classes_\n",
    "depressants_idx = list(class_names).index('Depressants')\n",
    "\n",
    "for dep_id in confirmed_depressants:\n",
    "    test_idx = dep_id - 501  # Convert submission ID to test index\n",
    "    pred = predictions[test_idx]\n",
    "    prob = prediction_probs[test_idx]\n",
    "    dep_prob = prob[depressants_idx]\n",
    "    \n",
    "    status = \"‚úì CAUGHT\" if pred == 'Depressants' else \"‚ùå MISSED\"\n",
    "    print(f\"ID {dep_id}: Predicted={pred}, Depressants_prob={dep_prob:.4f} {status}\")\n",
    "\n",
    "caught = sum(1 for dep_id in confirmed_depressants if predictions[dep_id - 501] == 'Depressants')\n",
    "print(f\"\\nSuccess Rate: {caught}/{len(confirmed_depressants)} ({100*caught/len(confirmed_depressants):.1f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391e969",
   "metadata": {},
   "source": [
    "## Create Submission File with IDs Starting from 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'ID': range(501, 501 + len(predictions)),  # IDs from 501 to 877\n",
    "    'drug_category': predictions\n",
    "})\n",
    "\n",
    "# Generate timestamp for filename\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'submission_BALANCED_3CLASS_{timestamp}.csv'\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"\\n‚úì Submission file created: {filename}\")\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nLast few rows:\")\n",
    "print(submission.tail(10))\n",
    "print(f\"\\nFinal prediction distribution:\")\n",
    "print(submission['drug_category'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(submission['drug_category'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87837c7d",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a55599",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Strategy: Balanced dataset (undersampling)\")\n",
    "print(f\"Original training samples: {len(train_df)}\")\n",
    "print(f\"Balanced training samples: {len(X_balanced)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nModel: Voting Ensemble (XGBoost + LightGBM + RF + GB)\")\n",
    "print(f\"Validation Accuracy: {voting_acc:.4f}\")\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"\\nPredicted Depressants: {(predictions == 'Depressants').sum()} ({100*(predictions == 'Depressants').sum()/len(predictions):.1f}%)\")\n",
    "print(f\"Predicted Hallucinogens: {(predictions == 'Hallucinogens').sum()} ({100*(predictions == 'Hallucinogens').sum()/len(predictions):.1f}%)\")\n",
    "print(f\"Predicted Stimulants: {(predictions == 'Stimulants').sum()} ({100*(predictions == 'Stimulants').sum()/len(predictions):.1f}%)\")\n",
    "print(f\"\\nConfirmed Depressants caught: {caught}/{len(confirmed_depressants)}\")\n",
    "print(f\"\\nSubmission file: {filename}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
